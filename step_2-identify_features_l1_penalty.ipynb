{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Identify Salient Features Using $\\ell1$-penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Data\n",
    "\n",
    "Prepared for the Neural Information Processing Symposium 2003 Feature Extraction Workshop\n",
    "\n",
    "http://clopinet.com/isabelle/Projects/NIPS2003\n",
    "\n",
    "MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear\n",
    "\n",
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.\n",
    "### Problem Statement\n",
    "\n",
    "Our dataset has 499 features to select from. Of those 499 there are 5 relevant features to provide us the highest output.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "Using machine learning technology, we will build algorithm models to find the optimal features. \n",
    "\n",
    "### Metric\n",
    "\n",
    "We will continue our process from our benchmarking phase by implementing an L1 penalty to the regression. \n",
    "### Benchmark\n",
    "\n",
    "Our benchmark for our test score will be provided from our previous benchmark scores of. \n",
    "\n",
    "Test Score  : 0.548484848485\n",
    "\n",
    "Train Score : 0.813432835821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('./lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, Ridge, SGDRegressor, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from project_5 import connect_to_postgres, load_data_from_database, make_data_dict, general_model, general_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = load_data_from_database('postgresql://dsi:correct horse battery staple@joshuacook.me:5432')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = make_data_dict(df.drop('label', axis=1), df['label'], 0.25, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model = general_model(LogisticRegression(penalty='l1'), data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.537878787879\n",
      "0.802985074627\n"
     ]
    }
   ],
   "source": [
    "print log_model['model']\n",
    "print log_model['test_score']\n",
    "print log_model['train_score']\n",
    "# print log_model['coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model_df = pd.DataFrame({'coef': log_model['model'].coef_[0],'features': log_model['X'].columns,\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.057896</td>\n",
       "      <td>feat_053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.045872</td>\n",
       "      <td>feat_471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.040498</td>\n",
       "      <td>feat_445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.036433</td>\n",
       "      <td>feat_472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.035307</td>\n",
       "      <td>feat_317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.034817</td>\n",
       "      <td>feat_474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.033552</td>\n",
       "      <td>feat_163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.030812</td>\n",
       "      <td>feat_196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.030368</td>\n",
       "      <td>feat_207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.029581</td>\n",
       "      <td>feat_189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  features\n",
       "53   0.057896  feat_053\n",
       "471  0.045872  feat_471\n",
       "445  0.040498  feat_445\n",
       "472  0.036433  feat_472\n",
       "317  0.035307  feat_317\n",
       "474  0.034817  feat_474\n",
       "163  0.033552  feat_163\n",
       "196  0.030812  feat_196\n",
       "207  0.030368  feat_207\n",
       "189  0.029581  feat_189"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/identify_features.png\" width=\"600px\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
